{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022/09/08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchmetrics import CohenKappa\n",
    "\n",
    "import gc\n",
    "\n",
    "from scipy import io\n",
    "import os\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: giqzsiko\n",
      "Sweep URL: https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "parameters_dict = {\n",
    "    'hidden_size': {\n",
    "        'values': [16,32,64]\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'values': [64]\n",
    "        },\n",
    "    'optimizer': {\n",
    "        'values': ['adam']\n",
    "        },\n",
    "    'epochs': {\n",
    "        'values': [400]\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        'values': [0.001,0.01]\n",
    "      }, \n",
    "    'chop': {\n",
    "        'values': [32,64,128]\n",
    "      }, \n",
    "    }\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"BEEE_KA_twosec_divide_DY_1007_1457_retry\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat_file(chop, option):\n",
    "    # mat_file = io.loadmat('/Users/goldenyoo/Library/Mobile Documents/com~apple~CloudDocs/BioCAS_prepare/Python_code/Data_center/one_dx/Calib_data_'+ str(num_subject) +'.mat')\n",
    "    # mat_file = io.loadmat('C:/Users/Peter/iCloudDrive/BioCAS_prepare/BCIIV_2a_mat/myData/Raw/Calib_data_'+ str(num_subject) +'_chop_'+str(chop) +'.mat')\n",
    "    \n",
    "    if option == 1:\n",
    "        file_name = f'C:/Users/Peter/Desktop/CGX/data/tmp/DY_KA_{chop}_twosec_data_1.mat'\n",
    "    elif option == 2:\n",
    "        file_name = f'C:/Users/Peter/Desktop/CGX/data/tmp/DY_KA_{chop}_twosec_data_2.mat'\n",
    "\n",
    "    mat_file = io.loadmat(file_name)\n",
    "\n",
    "    K1 = mat_file['K1']\n",
    "    K2 = mat_file['K2']\n",
    "\n",
    "    A1 = mat_file['A1']\n",
    "    A2 = mat_file['A2']\n",
    "    \n",
    "    Y1 = mat_file['Y1']\n",
    "    Y2 = mat_file['Y2']\n",
    "\n",
    "    # K 특성에 대한 Class1 vs Class2 Data 가져오기\n",
    "    k1 = torch.FloatTensor(K1)\n",
    "    k2 = torch.FloatTensor(K2)\n",
    "    a1 = torch.FloatTensor(A1)\n",
    "    a2 = torch.FloatTensor(A2)\n",
    "\n",
    "\n",
    "    # Y에 대한 Class1 vs Class2 Data 가져오기\n",
    "    y1 = torch.LongTensor(Y1)\n",
    "    y2 = torch.LongTensor(Y2)\n",
    "\n",
    "    k_train = torch.cat([k1,k2],dim=0)\n",
    "    a_train = torch.cat([a1,a2],dim=0)\n",
    "\n",
    "    y_train = torch.cat([y1,y2],dim=0)\n",
    "    y_train = y_train-1 # y를 0~1의 정수로 만들어야함.\n",
    "\n",
    "\n",
    "\n",
    "    return k_train.to(device), a_train.to(device), y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(batch_size, k_train, a_train, y_train, k_test, a_test, y_test):\n",
    "    dataset_train = TensorDataset(k_train, a_train, y_train) # 각 tensor의 첫번째 dim이 일치해야한다\n",
    "    dataset_test = TensorDataset(k_test, a_test, y_test) # 각 tensor의 첫번째 dim이 일치해야한다\n",
    "\n",
    "    # Data Split\n",
    "    dataset_size = len(dataset_train)\n",
    "    train_size = int(dataset_size * 0.8)\n",
    "    valid_size = dataset_size - train_size\n",
    "\n",
    "    train_dataset, valid_dataset = random_split(dataset_train, [train_size, valid_size])\n",
    "\n",
    "    train_DL = DataLoader(train_dataset, batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "    valid_DL = DataLoader(valid_dataset, batch_size= valid_size, shuffle=False)\n",
    "\n",
    "    test_DL = DataLoader(dataset_test, batch_size = batch_size )\n",
    "\n",
    "\n",
    "    return train_DL, valid_DL, test_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 19\n",
    "n_class = 2\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "class TextLSTM(nn.Module):\n",
    "  def __init__(self,hidden_size):\n",
    "    super(TextLSTM, self).__init__()\n",
    "\n",
    "    self.lstm_1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "    self.lstm_2 = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "    self.fc_1 = nn.Linear(hidden_size*2, hidden_size*2)\n",
    "    self.fc_2 = nn.Linear(hidden_size*2, n_class)\n",
    "\n",
    "  def forward(self,  K_and_A):\n",
    "    (k, a) = K_and_A\n",
    "\n",
    "    k.transpose_(0,1)\n",
    "    k.transpose_(0,2)\n",
    "    a.transpose_(0,1)\n",
    "    a.transpose_(0,2)\n",
    "\n",
    "    outputs1, (h_n1,c_n1) = self.lstm_1(k)\n",
    "    outputs2, (h_n2,c_n2) = self.lstm_2(a)\n",
    "\n",
    "    outputs = torch.cat((outputs1[-1],outputs2[-1]), dim=1)  \n",
    "\n",
    "    x = self.fc_1(outputs)  # 최종 예측 최종 출력 층\n",
    "    model = self.fc_2(F.relu(x))\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        k_train, a_train, y_train = load_mat_file(config.chop, 1)\n",
    "        k_test, a_test, y_test = load_mat_file(config.chop, 2)\n",
    "\n",
    "        model = TextLSTM(hidden_size=config.hidden_size).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        train_DL, valid_DL, test_DL = build_dataset(config.batch_size, k_train.to(device), a_train.to(device), y_train.to(device),k_test.to(device), a_test.to(device), y_test.to(device))\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            rloss = 0\n",
    "            model.train()\n",
    "            for batch_idx, samples in enumerate(train_DL):\n",
    "\n",
    "                k_train_mb, a_train_mb, y_train_mb = samples\n",
    "\n",
    "                # Forward\n",
    "                output = model((k_train_mb.to(device),a_train_mb.to(device)))\n",
    "\n",
    "                # Cost\n",
    "                loss = criterion(output.to(device), y_train_mb.squeeze().to(device))\n",
    "\n",
    "                # Backpropagate\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_b = loss.item()*config.batch_size\n",
    "                rloss += float(loss_b)\n",
    "            # For each epoch end\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # epoch loss \n",
    "                loss_e = rloss/len(train_DL.dataset) \n",
    "                \n",
    "                # # Validation\n",
    "                # k_valid, a_valid, y_valid = next(iter(valid_DL))\n",
    "\n",
    "                # output = model( (k_valid.to(device),a_valid.to(device)))\n",
    "                # prediction = output.argmax(dim=1)\n",
    "                # correct = prediction.eq(y_valid.view_as(prediction)).sum().item()\n",
    "\n",
    "                # # Wandb log\n",
    "                # wandb.log({\"loss\": loss_e})\n",
    "                # wandb.log({\"Validation accuracy\": correct/len(valid_DL.dataset)})\n",
    "\n",
    "                if epoch % 100 == 0:\n",
    "                    print(f\"Epoch: {epoch}, train loss: {round(loss_e,3)}\")\n",
    "                    # print(f\"Validation accuracy: {round(correct/len(valid_DL.dataset),3)}\")\n",
    "\n",
    "\n",
    "\n",
    "            scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            t_correct = 0\n",
    "            for batch_idx, samples in enumerate(test_DL):\n",
    "                k_train_mb, a_train_mb, y_train_mb = samples\n",
    "\n",
    "                output = model( (k_train_mb.to(device),a_train_mb.to(device)))\n",
    "                prediction = output.argmax(dim=1)\n",
    "                correct = prediction.eq(y_train_mb.view_as(prediction)).sum().item()\n",
    "                t_correct += correct\n",
    "                # cohenkappa = CohenKappa(num_classes=2).to(device)\n",
    "                # peter_kappa = cohenkappa(prediction, y_train_mb.view_as(prediction))\n",
    "                # wandb.log({\"Kappa\": peter_kappa.item()})\n",
    "            print(f\"Evaluation accuracy: {round(t_correct/len(test_DL.dataset),3)}\")\n",
    "            wandb.log({\"Evaluation accuracy\": t_correct/len(test_DL.dataset)})\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cj7kpho6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgoldenyoo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_145844-cj7kpho6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/cj7kpho6\" target=\"_blank\">easy-sweep-1</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.691\n",
      "Validation accuracy: 0.524\n",
      "Epoch: 100, train loss: 0.509\n",
      "Validation accuracy: 0.636\n",
      "Epoch: 200, train loss: 0.508\n",
      "Validation accuracy: 0.636\n",
      "Epoch: 300, train loss: 0.508\n",
      "Validation accuracy: 0.636\n",
      "Evaluation accuracy: 0.486\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▄▇▇█▇▇█████████████████████████████████</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.48563</td></tr><tr><td>Validation accuracy</td><td>0.63649</td></tr><tr><td>loss</td><td>0.5077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">easy-sweep-1</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/cj7kpho6\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/cj7kpho6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_145844-cj7kpho6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vyrjajb8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_150506-vyrjajb8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/vyrjajb8\" target=\"_blank\">swept-sweep-2</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.69\n",
      "Validation accuracy: 0.518\n",
      "Epoch: 100, train loss: 0.134\n",
      "Validation accuracy: 0.86\n",
      "Epoch: 200, train loss: 0.129\n",
      "Validation accuracy: 0.859\n",
      "Epoch: 300, train loss: 0.129\n",
      "Validation accuracy: 0.859\n",
      "Evaluation accuracy: 0.501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▂▆▇████████████████████████████████████</td></tr><tr><td>loss</td><td>██▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.50068</td></tr><tr><td>Validation accuracy</td><td>0.85943</td></tr><tr><td>loss</td><td>0.12925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swept-sweep-2</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/vyrjajb8\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/vyrjajb8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_150506-vyrjajb8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8feuf6nl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_151124-8feuf6nl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/8feuf6nl\" target=\"_blank\">ethereal-sweep-3</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.686\n",
      "Validation accuracy: 0.557\n",
      "Epoch: 100, train loss: 0.061\n",
      "Validation accuracy: 0.868\n",
      "Epoch: 200, train loss: 0.058\n",
      "Validation accuracy: 0.868\n",
      "Epoch: 300, train loss: 0.059\n",
      "Validation accuracy: 0.868\n",
      "Evaluation accuracy: 0.514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▄▇▇████████████████████████████████████</td></tr><tr><td>loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.51368</td></tr><tr><td>Validation accuracy</td><td>0.86828</td></tr><tr><td>loss</td><td>0.05828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-3</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/8feuf6nl\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/8feuf6nl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_151124-8feuf6nl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xf7kkbbu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_151742-xf7kkbbu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/xf7kkbbu\" target=\"_blank\">zesty-sweep-4</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.688\n",
      "Validation accuracy: 0.552\n",
      "Epoch: 100, train loss: 0.0\n",
      "Validation accuracy: 0.953\n",
      "Epoch: 200, train loss: 0.0\n",
      "Validation accuracy: 0.953\n",
      "Epoch: 300, train loss: 0.0\n",
      "Validation accuracy: 0.953\n",
      "Evaluation accuracy: 0.515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▂▇█████████████████████████████████████</td></tr><tr><td>loss</td><td>██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.51484</td></tr><tr><td>Validation accuracy</td><td>0.95269</td></tr><tr><td>loss</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zesty-sweep-4</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/xf7kkbbu\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/xf7kkbbu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_151742-xf7kkbbu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wo9setqa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_152344-wo9setqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/wo9setqa\" target=\"_blank\">misty-sweep-5</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.68\n",
      "Validation accuracy: 0.58\n",
      "Epoch: 100, train loss: 0.0\n",
      "Validation accuracy: 0.97\n",
      "Epoch: 200, train loss: 0.0\n",
      "Validation accuracy: 0.971\n",
      "Epoch: 300, train loss: 0.0\n",
      "Validation accuracy: 0.971\n",
      "Evaluation accuracy: 0.533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.53254</td></tr><tr><td>Validation accuracy</td><td>0.97141</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-sweep-5</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/wo9setqa\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/wo9setqa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_152344-wo9setqa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jajrum4n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_152956-jajrum4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/jajrum4n\" target=\"_blank\">sunny-sweep-6</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.689\n",
      "Validation accuracy: 0.546\n",
      "Epoch: 100, train loss: 0.123\n",
      "Validation accuracy: 0.625\n",
      "Epoch: 200, train loss: 0.114\n",
      "Validation accuracy: 0.627\n",
      "Epoch: 300, train loss: 0.114\n",
      "Validation accuracy: 0.627\n",
      "Evaluation accuracy: 0.501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▄▆███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>loss</td><td>██▇▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.50054</td></tr><tr><td>Validation accuracy</td><td>0.6273</td></tr><tr><td>loss</td><td>0.11396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-sweep-6</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/jajrum4n\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/jajrum4n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_152956-jajrum4n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81jxcclg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_153609-81jxcclg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/81jxcclg\" target=\"_blank\">youthful-sweep-7</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.691\n",
      "Validation accuracy: 0.514\n",
      "Epoch: 100, train loss: 0.551\n",
      "Validation accuracy: 0.608\n",
      "Epoch: 200, train loss: 0.551\n",
      "Validation accuracy: 0.608\n",
      "Epoch: 300, train loss: 0.551\n",
      "Validation accuracy: 0.608\n",
      "Evaluation accuracy: 0.491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▄▆▇███▇████████████████████████████████</td></tr><tr><td>loss</td><td>█▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.49149</td></tr><tr><td>Validation accuracy</td><td>0.60824</td></tr><tr><td>loss</td><td>0.55109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">youthful-sweep-7</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/81jxcclg\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/81jxcclg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_153609-81jxcclg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p9799ag7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_154253-p9799ag7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p9799ag7\" target=\"_blank\">logical-sweep-8</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.693\n",
      "Validation accuracy: 0.508\n",
      "Epoch: 100, train loss: 0.038\n",
      "Validation accuracy: 0.957\n",
      "Epoch: 200, train loss: 0.035\n",
      "Validation accuracy: 0.957\n",
      "Epoch: 300, train loss: 0.035\n",
      "Validation accuracy: 0.957\n",
      "Evaluation accuracy: 0.503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▁▇█████████████████████████████████████</td></tr><tr><td>loss</td><td>██▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.50334</td></tr><tr><td>Validation accuracy</td><td>0.95745</td></tr><tr><td>loss</td><td>0.03499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">logical-sweep-8</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p9799ag7\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p9799ag7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_154253-p9799ag7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3dsxs2pf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_155030-3dsxs2pf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/3dsxs2pf\" target=\"_blank\">fresh-sweep-9</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.689\n",
      "Validation accuracy: 0.529\n",
      "Epoch: 100, train loss: 0.252\n",
      "Validation accuracy: 0.735\n",
      "Epoch: 200, train loss: 0.249\n",
      "Validation accuracy: 0.737\n",
      "Epoch: 300, train loss: 0.249\n",
      "Validation accuracy: 0.737\n",
      "Evaluation accuracy: 0.498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▃▅▆▇▇██████████████████████████████████</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.49837</td></tr><tr><td>Validation accuracy</td><td>0.73724</td></tr><tr><td>loss</td><td>0.2491</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-sweep-9</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/3dsxs2pf\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/3dsxs2pf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_155030-3dsxs2pf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w9gx0hio with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_155703-w9gx0hio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/w9gx0hio\" target=\"_blank\">resilient-sweep-10</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.691\n",
      "Validation accuracy: 0.52\n",
      "Epoch: 100, train loss: 0.092\n",
      "Validation accuracy: 0.851\n",
      "Epoch: 200, train loss: 0.085\n",
      "Validation accuracy: 0.851\n",
      "Epoch: 300, train loss: 0.085\n",
      "Validation accuracy: 0.851\n",
      "Evaluation accuracy: 0.494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>▁</td></tr><tr><td>Validation accuracy</td><td>▁▁▄▇▇███████████████████████████████████</td></tr><tr><td>loss</td><td>██▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Evaluation accuracy</td><td>0.49353</td></tr><tr><td>Validation accuracy</td><td>0.85058</td></tr><tr><td>loss</td><td>0.08506</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">resilient-sweep-10</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/w9gx0hio\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/w9gx0hio</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_155703-w9gx0hio\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fm7x8axz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160336-fm7x8axz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/fm7x8axz\" target=\"_blank\">restful-sweep-11</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-sweep-11</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/fm7x8axz\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/fm7x8axz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160336-fm7x8axz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run fm7x8axz errored: RuntimeError('CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 3.00 GiB total capacity; 411.39 MiB already allocated; 662.05 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run fm7x8axz errored: RuntimeError('CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 3.00 GiB total capacity; 411.39 MiB already allocated; 662.05 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p27u8bop with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160402-p27u8bop</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p27u8bop\" target=\"_blank\">gentle-sweep-12</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-sweep-12</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p27u8bop\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/p27u8bop</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160402-p27u8bop\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run p27u8bop errored: RuntimeError('CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 3.00 GiB total capacity; 714.38 MiB already allocated; 660.05 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run p27u8bop errored: RuntimeError('CUDA out of memory. Tried to allocate 930.00 MiB (GPU 0; 3.00 GiB total capacity; 714.38 MiB already allocated; 660.05 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e17nrn25 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160423-e17nrn25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/e17nrn25\" target=\"_blank\">quiet-sweep-13</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-sweep-13</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/e17nrn25\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/e17nrn25</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160423-e17nrn25\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run e17nrn25 errored: RuntimeError('CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 3.00 GiB total capacity; 1.30 GiB already allocated; 0 bytes free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run e17nrn25 errored: RuntimeError('CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 3.00 GiB total capacity; 1.30 GiB already allocated; 0 bytes free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: krhmy7b8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160444-krhmy7b8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/krhmy7b8\" target=\"_blank\">snowy-sweep-14</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-14</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/krhmy7b8\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/krhmy7b8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160444-krhmy7b8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run krhmy7b8 errored: RuntimeError('CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 3.00 GiB total capacity; 1.88 GiB already allocated; 0 bytes free; 1.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run krhmy7b8 errored: RuntimeError('CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 3.00 GiB total capacity; 1.88 GiB already allocated; 0 bytes free; 1.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zjqsxdko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160507-zjqsxdko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/zjqsxdko\" target=\"_blank\">swift-sweep-15</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-15</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/zjqsxdko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/zjqsxdko</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160507-zjqsxdko\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run zjqsxdko errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run zjqsxdko errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 63vf3upk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160537-63vf3upk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/63vf3upk\" target=\"_blank\">solar-sweep-16</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-sweep-16</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/63vf3upk\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/63vf3upk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160537-63vf3upk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 63vf3upk errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 63vf3upk errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r9lngtwa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160558-r9lngtwa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/r9lngtwa\" target=\"_blank\">tough-sweep-17</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tough-sweep-17</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/r9lngtwa\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/r9lngtwa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160558-r9lngtwa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run r9lngtwa errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run r9lngtwa errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ztr09lrh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20221007_160619-ztr09lrh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/ztr09lrh\" target=\"_blank\">lunar-sweep-18</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/sweeps/giqzsiko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-sweep-18</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/ztr09lrh\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_KA_twosec_divide_DY_1007_1457_retry/runs/ztr09lrh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221007_160619-ztr09lrh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ztr09lrh errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ztr09lrh errored: RuntimeError('CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 3.00 GiB total capacity; 1.97 GiB already allocated; 0 bytes free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Car')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3299b8f52885fadf7695044421d8db9b9b3474af12aaae4218ce23d61e72ab48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
