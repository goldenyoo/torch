{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldenyoo/miniforge3/envs/mac_cpu/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"i like dog\", \"i love coffee\", \"i hate milk\", \"you like cat\", \"you love milk\", \"you hate coffee\"]\n",
    "dtype = torch.float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(sentences).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(\" \".join(sentences).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(\" \".join(sentences).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "for i, w in enumerate(word_list):\n",
    "    print(i)\n",
    "    print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Word Processing\n",
    "\"\"\"\n",
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/3wjwv6195cb09tvny8_v_7_m0000gn/T/ipykernel_44764/626710555.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1647804319176/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  input_batch = torch.tensor(input_batch, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "TextRNN Parameter\n",
    "\"\"\"\n",
    "batch_size = len(sentences)\n",
    "n_step = 2  # 학습 하려고 하는 문장의 길이 - 1\n",
    "n_hidden = 5  # 은닉층 사이즈\n",
    "\n",
    "def make_batch(sentences):\n",
    "  input_batch = []\n",
    "  target_batch = []\n",
    "\n",
    "  for sen in sentences:\n",
    "    word = sen.split()\n",
    "    input = [word_dict[n] for n in word[:-1]]\n",
    "    target = word_dict[word[-1]]\n",
    "\n",
    "    input_batch.append(np.eye(n_class)[input])  # One-Hot Encoding\n",
    "    target_batch.append(target)\n",
    "  \n",
    "  return input_batch, target_batch\n",
    "\n",
    "input_batch, target_batch = make_batch(sentences)\n",
    "input_batch = torch.tensor(input_batch, dtype=torch.float32, requires_grad=True)\n",
    "target_batch = torch.tensor(target_batch, dtype=torch.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "TextLSTM\n",
    "\"\"\"\n",
    "class TextLSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TextLSTM, self).__init__()\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, dropout=0.3)\n",
    "    self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    # self.W = nn.Parameter(torch.randn([n_hidden, n_class]).type(dtype))\n",
    "    # self.b = nn.Parameter(torch.randn([n_class]).type(dtype))\n",
    "    # self.Softmax = nn.Softmax(dim=1) # softmax 포함되어있다고 하지 않았나? CrossEntropyLoss에...\n",
    "\n",
    "  def forward(self, hidden_and_cell, X):\n",
    "    X = X.transpose(0, 1)\n",
    "    # outputs, hidden = self.lstm(X, hidden_and_cell)\n",
    "    # outputs = outputs[-1]  # 최종 예측 Hidden Layer\n",
    "    # print(X.size())\n",
    "    outputs, (h_n,c_n) = self.lstm(X, hidden_and_cell)\n",
    "    \n",
    "    outputs = h_n[-1]  # 최종 예측 Hidden Layer\n",
    "    # print(outputs.size())\n",
    "\n",
    "    # model = torch.mm(outputs, self.W) + self.b  # 최종 예측 최종 출력 층\n",
    "    model = self.fc(outputs)  # 최종 예측 최종 출력 층\n",
    "    \n",
    "    return model\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldenyoo/miniforge3/envs/mac_cpu/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 cost = 0.473329\n",
      "Epoch: 0200 cost = 0.045445\n",
      "Epoch: 0300 cost = 0.018823\n",
      "Epoch: 0400 cost = 0.011123\n",
      "Epoch: 0500 cost = 0.007530\n",
      "[['i', 'like'], ['i', 'love'], ['i', 'hate'], ['you', 'like'], ['you', 'love'], ['you', 'hate']] -> ['dog', 'coffee', 'milk', 'cat', 'milk', 'coffee']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "model = TextLSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(500):\n",
    "  hidden = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n",
    "  cell = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n",
    "  output = model((hidden, cell), input_batch)\n",
    "  loss = criterion(output, target_batch)\n",
    "\n",
    "  if (epoch + 1) % 100 == 0:\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "input = [sen.split()[:2] for sen in sentences]\n",
    "\n",
    "hidden = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n",
    "cell = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n",
    "predict = model((hidden, cell), input_batch).data.max(1, keepdim=True)[1]\n",
    "print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lstm.weight_ih_l0',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.2959e-01,  1.2352e+00,  1.4425e+00,  2.1049e-01, -1.4144e-01,\n",
       "            9.3685e-01,  6.6125e-02, -1.8781e-01,  1.3220e-01],\n",
       "          [ 2.0392e-01,  1.4550e-01,  1.2286e+00,  4.5497e-01, -1.0107e-01,\n",
       "            1.0979e+00,  8.3179e-01, -1.3570e-01,  4.0171e-01],\n",
       "          [ 2.0629e-01,  6.7606e-01,  1.5959e+00,  4.3274e-01, -5.5717e-02,\n",
       "            3.7154e-01,  1.0130e+00,  1.6352e-01, -1.9693e-01],\n",
       "          [-3.4550e-01, -1.8735e-01,  7.6785e-01,  9.4921e-01, -4.0330e-01,\n",
       "            8.1932e-01,  7.9812e-01, -4.2112e-01,  1.5220e-01],\n",
       "          [-2.9098e-01,  1.1089e+00,  1.8268e+00, -2.1308e+00, -3.3672e-01,\n",
       "            1.5863e+00,  6.4966e-01, -3.4723e-01, -3.3569e-01],\n",
       "          [ 2.9612e-02,  5.6132e-01, -1.7194e-01, -1.5424e+00,  1.9196e-01,\n",
       "            2.3765e-01,  3.3198e+00, -3.3491e-01,  1.2823e-01],\n",
       "          [-3.7450e-01, -1.4594e+00,  4.2409e-01,  1.8632e+00,  1.1670e-01,\n",
       "           -3.5461e-01,  2.4244e+00, -3.1852e-01,  6.9584e-02],\n",
       "          [ 4.2745e-01, -1.6967e+00, -3.1755e-01,  1.9065e+00,  3.3160e-02,\n",
       "            2.4578e-02,  2.8994e-01,  3.2668e-01, -1.4654e-02],\n",
       "          [ 2.9976e-01, -1.5928e+00, -1.3093e-01, -5.0870e-01,  1.9493e-01,\n",
       "            4.2959e-01,  2.1179e+00, -3.5783e-01, -4.4319e-01],\n",
       "          [-1.8662e-01,  6.6601e-01,  4.3965e-01, -2.7428e+00,  3.1228e-01,\n",
       "           -8.4760e-02,  2.1683e+00,  2.1941e-01, -4.5192e-02],\n",
       "          [-1.2374e-01, -5.3206e-01, -5.0972e-01,  1.5677e+00, -4.4351e-01,\n",
       "           -4.9882e-01, -1.6500e+00,  3.9437e-01, -6.1361e-02],\n",
       "          [ 1.2267e-01, -1.6089e+00,  6.9959e-01,  1.0655e+00,  1.4603e-01,\n",
       "            7.1085e-01,  8.9411e-01,  1.4850e-01,  3.6031e-01],\n",
       "          [ 7.5491e-02, -1.4064e+00,  9.9721e-01,  1.3949e+00,  2.3005e-01,\n",
       "            8.1874e-01,  1.7424e-01, -2.9785e-01,  3.6654e-01],\n",
       "          [-3.2619e-01,  8.6618e-01, -4.7968e-01,  1.6547e-03, -3.3717e-01,\n",
       "           -9.6859e-01, -2.1059e+00,  3.9212e-01, -4.4217e-01],\n",
       "          [-4.1083e-04,  1.4019e+00,  1.2953e+00, -2.0875e+00, -3.4695e-02,\n",
       "           -2.0970e+00,  4.7772e-01, -7.7607e-03, -1.0189e-01],\n",
       "          [ 1.6356e-01,  1.2345e+00,  1.1851e+00,  3.5657e-01,  3.9940e-01,\n",
       "            5.6853e-01,  1.0168e+00,  1.9446e-01, -1.2913e-01],\n",
       "          [-2.7303e-01, -3.8258e-01,  8.7663e-01,  2.8467e-01, -1.1906e-01,\n",
       "            9.4645e-01,  2.8381e-01, -9.2696e-02,  3.8481e-01],\n",
       "          [-2.5337e-01,  9.9583e-01,  1.1385e+00,  5.5174e-01, -4.3837e-01,\n",
       "            4.7011e-01,  4.3786e-01,  2.4089e-01, -2.1667e-01],\n",
       "          [-1.3160e-01,  6.7778e-02,  8.8872e-01,  9.3765e-01, -3.4699e-01,\n",
       "            4.1358e-01,  3.6608e-01, -3.5492e-01, -1.3405e-01],\n",
       "          [-1.6170e-01,  4.7391e-01,  1.4563e+00, -2.0727e+00,  3.6388e-01,\n",
       "            1.7650e+00,  2.0146e+00,  7.6357e-02,  4.9406e-02]],\n",
       "         requires_grad=True)),\n",
       " ('lstm.weight_hh_l0',\n",
       "  Parameter containing:\n",
       "  tensor([[-1.1508,  1.0103,  1.2393, -1.6797, -0.6120],\n",
       "          [-1.5843,  0.7312,  1.2398, -1.5278, -0.9372],\n",
       "          [-1.1144,  1.0980,  0.8580, -0.9602, -1.1169],\n",
       "          [-1.5921,  1.3070,  1.3287, -1.1339,  0.8949],\n",
       "          [-0.1098,  0.3760,  0.6410, -0.6589,  2.9058],\n",
       "          [-0.1865,  0.2711,  0.7368, -0.3322,  3.0386],\n",
       "          [ 0.4675, -0.4353, -0.1143,  0.4960,  0.5035],\n",
       "          [-0.8104, -0.1429,  0.4035,  0.6093,  2.1128],\n",
       "          [ 0.5095,  0.6103, -0.4099, -1.3873, -2.6470],\n",
       "          [ 0.5394,  0.2672,  0.1233, -0.4210,  0.2222],\n",
       "          [ 0.0458,  0.0739, -0.2615, -0.2573, -2.4216],\n",
       "          [-0.2016, -0.0397, -0.6028,  0.7838,  0.1379],\n",
       "          [-0.8048, -0.0115,  0.0187,  0.6347,  1.9574],\n",
       "          [-0.1408,  0.2408,  0.1810, -0.3991,  2.0497],\n",
       "          [ 0.3350, -0.3588, -0.4228,  0.3238,  1.5950],\n",
       "          [-1.5985,  1.2577,  1.1181, -1.2584,  0.0504],\n",
       "          [-1.8825,  0.9645,  1.3057, -0.8714, -0.6868],\n",
       "          [-1.5420,  1.2580,  0.9115, -1.6136, -0.4345],\n",
       "          [-1.7410,  0.7848,  1.1889, -0.7660,  1.0079],\n",
       "          [-0.5030,  0.5647,  0.7747, -0.1318,  2.8199]], requires_grad=True)),\n",
       " ('lstm.bias_ih_l0',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.6232,  1.1605,  0.6623,  1.2097,  0.8128,  0.1525,  0.1186,  0.3977,\n",
       "           0.4863, -0.0192, -0.6213,  0.6768,  0.5223, -0.4628,  0.1885,  1.2493,\n",
       "           0.7780,  0.6290,  0.6248,  1.2181], requires_grad=True)),\n",
       " ('lstm.bias_hh_l0',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.4926,  1.0679,  1.0039,  1.2037,  1.2839,  0.0059,  0.0048,  0.0151,\n",
       "           0.0324, -0.2564, -0.8396,  0.2136,  0.4808, -0.7689,  0.2291,  0.5802,\n",
       "           1.1626,  0.8278,  0.6595,  0.7472], requires_grad=True)),\n",
       " ('fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.2471e+00,  1.4705e+00,  2.4392e+00, -2.3717e+00,  2.2955e+00],\n",
       "          [ 1.0113e+00, -3.4611e-01, -7.2472e-01,  6.5175e-01,  2.3797e-03],\n",
       "          [ 1.5185e+00, -4.4324e-01, -6.1134e-01,  6.6733e-01, -1.2011e-02],\n",
       "          [ 1.0764e+00, -8.3698e-01, -6.5348e-01,  1.2648e+00, -3.1471e-01],\n",
       "          [-2.1312e+00,  1.6332e+00,  7.3304e-01,  3.2282e-02, -2.5539e+00],\n",
       "          [ 1.0471e+00, -6.0078e-01, -8.5365e-01,  1.1490e+00, -3.7715e-01],\n",
       "          [ 1.6110e+00, -6.7278e-01, -8.1764e-01,  8.1667e-01, -5.9490e-02],\n",
       "          [-1.2529e+00, -2.0158e+00,  1.2465e-01,  2.2594e+00,  2.2853e+00],\n",
       "          [-8.2413e-01, -2.7019e+00, -2.4119e+00, -9.0856e-01, -4.1674e-01]],\n",
       "         requires_grad=True)),\n",
       " ('fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3377, -0.7603, -0.4215, -0.8740,  0.3867, -0.6440, -0.2221,  1.0177,\n",
       "           1.6221], requires_grad=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mac_cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a25b673604e404bbe71cb44188daddb26f9dca9dc7a0ddb839fa50ca7e9deea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
