{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from scipy import io\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "from peter_functions_tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "\n",
    "parameters_dict = {\n",
    "    'hidden_size': {\n",
    "        'values': [16,32,64]\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'values': [128]\n",
    "        },\n",
    "    'optimizer': {\n",
    "        'values': ['adam']\n",
    "        },\n",
    "    'epochs': {\n",
    "        'values': [500]\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        'values': [0.001,0.01]\n",
    "      }, \n",
    "    'chop': {\n",
    "        'values': [32,64,128]\n",
    "      }, \n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변경해야하는 변수 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pzq16oio\n",
      "Sweep URL: https://wandb.ai/goldenyoo/BEEE_short/sweeps/pzq16oio\n"
     ]
    }
   ],
   "source": [
    "input_size  = 8\n",
    "n_class     = 2\n",
    "proj_name   = \"BEEE_short\"\n",
    "file_path = \"C:/Users/Peter/Desktop/CGX/data/less_aug\"\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLSTM(nn.Module):\n",
    "  def __init__(self,hidden_size):\n",
    "    super(TextLSTM, self).__init__()\n",
    "\n",
    "    self.lstm_1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "    self.lstm_2 = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "    self.fc_1 = nn.Linear(hidden_size*2, hidden_size*2)\n",
    "    self.fc_2 = nn.Linear(hidden_size*2, n_class)\n",
    "\n",
    "  def forward(self, hidden_and_cell_k, hidden_and_cell_a, K_and_A):\n",
    "    (k, a) = K_and_A\n",
    "\n",
    "    k.transpose_(0,1)\n",
    "    k.transpose_(0,2)\n",
    "    a.transpose_(0,1)\n",
    "    a.transpose_(0,2)\n",
    "\n",
    "    outputs1, (h_n1,c_n1) = self.lstm_1(k, hidden_and_cell_k)\n",
    "    outputs2, (h_n2,c_n2) = self.lstm_2(a, hidden_and_cell_a)\n",
    "\n",
    "    outputs = torch.cat((outputs1[-1],outputs2[-1]), dim=1)  \n",
    "\n",
    "    x = self.fc_1(outputs)  # 최종 예측 최종 출력 층\n",
    "    model = self.fc_2(F.relu(x))\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_agent_run(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        k_train, a_train, y_train   = load_mat_file(config.chop, file_path, 1)\n",
    "        k_test, a_test, y_test      = load_mat_file(config.chop, file_path, 2)\n",
    "        train_DL, val_DL, test_DL, tf_DL   = build_dataset_tf(config.batch_size, k_train.to(DEVICE), a_train.to(DEVICE), y_train.to(DEVICE),k_test.to(DEVICE), a_test.to(DEVICE), y_test.to(DEVICE))\n",
    "        \n",
    "        model = TextLSTM(hidden_size=config.hidden_size).to(DEVICE)\n",
    "        \n",
    "        Train(model, train_DL, val_DL, config)\n",
    "        Test (model, test_DL, config)\n",
    "\n",
    "        Train_tf(model, tf_DL, config = config)\n",
    "        Test (model, test_DL, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: etsmznss with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgoldenyoo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20220909_142834-etsmznss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_short/runs/etsmznss\" target=\"_blank\">celestial-sweep-1</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_short\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_short/sweeps/pzq16oio\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_short/sweeps/pzq16oio</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">celestial-sweep-1</strong>: <a href=\"https://wandb.ai/goldenyoo/BEEE_short/runs/etsmznss\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_short/runs/etsmznss</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220909_142834-etsmznss\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run etsmznss errored: RuntimeError('input.size(-1) must be equal to input_size. Expected 22, got 8')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run etsmznss errored: RuntimeError('input.size(-1) must be equal to input_size. Expected 22, got 8')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c275r6x2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchop: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Peter\\Desktop\\torch_git\\wandb\\run-20220909_142855-c275r6x2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/goldenyoo/BEEE_short/runs/c275r6x2\" target=\"_blank\">twilight-sweep-2</a></strong> to <a href=\"https://wandb.ai/goldenyoo/BEEE_short\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/goldenyoo/BEEE_short/sweeps/pzq16oio\" target=\"_blank\">https://wandb.ai/goldenyoo/BEEE_short/sweeps/pzq16oio</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, One_agent_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Car')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3299b8f52885fadf7695044421d8db9b9b3474af12aaae4218ce23d61e72ab48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
